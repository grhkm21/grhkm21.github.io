<!DOCTYPE html>
<html lang="en-uk">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Short article on nonlinear regression, focusing on polynomial models. Written for HS students.'><title>Nonlinear Regression (1)</title>

<link rel='canonical' href='https://grhkm21.github.io/posts/nonlinear-regression/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='Nonlinear Regression (1)'>
<meta property='og:description' content='Short article on nonlinear regression, focusing on polynomial models. Written for HS students.'>
<meta property='og:url' content='https://grhkm21.github.io/posts/nonlinear-regression/'>
<meta property='og:site_name' content='Blog by grhkm21'>
<meta property='og:type' content='article'><meta property='article:section' content='Posts' /><meta property='article:published_time' content='2022-07-12T23:29:12&#43;08:00'/><meta property='article:modified_time' content='2022-07-12T23:29:12&#43;08:00'/>
<meta name="twitter:site" content="@grhkm2023">
    <meta name="twitter:creator" content="@grhkm2023"><meta name="twitter:title" content="Nonlinear Regression (1)">
<meta name="twitter:description" content="Short article on nonlinear regression, focusing on polynomial models. Written for HS students.">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6BP6QGT61V"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-6BP6QGT61V');
</script>
    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="https://grhkm21.github.io/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <h2 class="article-title">
        <a href="/posts/nonlinear-regression/">Nonlinear Regression (1)</a>
    </h2>

    
    <h3 class="article-subtitle">
        Short article on nonlinear regression, focusing on polynomial models. Written for HS students.
    </h3>
    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jul 12, 2022</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    8 minute read
                </time>
            </div>
        
    </footer>
    
</div>
</header>
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };

    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function (x) {
            x.parentElement.classList += 'has-jax'
        })
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <section class="article-content">
    <h1 id="notes-on-non-linear-regression">Notes on Non-Linear Regression</h1>
<h2 id="1-linear-regression">1. Linear Regression</h2>
<p>To begin, let&rsquo;s recall how linear regression is done. We are given $n$ <strong>data points</strong> $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$, and we are to make a linear <strong>model</strong></p>
<p>$$
f(x) = ax + b
$$</p>
<p>Such that the model &ldquo;closely approximates&rdquo; the data points, that is, to have $y_i \sim f(x_i)$. The <strong>residual</strong> is defined as the absolute difference between the interpolated data and the actual data:</p>
<p>$$
r_i := y_i - f(x_i) = y_i - (ax_i + b)
$$</p>
<p>To mathematically define &ldquo;closely approximates&rdquo;, we will need the notion of error measures. There are many types of such measures, such as averaging the absolute value of the residuals or using the maximum residual. However, in this page we will use the following measure, analogous to <em>standard deviation</em> in Statistics:</p>
<p>$$
E_2(f) := \sqrt{\frac{1}{n}\sum_{i=1}^n r_i^2}
$$</p>
<p>The functional $E_2$ is called the Root Mean Square error, abbreviated RMS below. With this notion, we can formalise the problem of linear regression:</p>

<div class="alert alert-info" role="alert"><p><strong>Linear Regression:</strong> Given $n$ points $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$, find coefficients $a, b$ such that for the model $f(x) = ax + b$, the RMS</p>
<p>$$
E_2(f) = \sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - f(x_i))^2}
$$</p>
<p>is minimised.</p>
</div>

<hr>
<h2 id="2-polynomial-regression">2. Polynomial Regression</h2>
<p>With the formalisation, it is easy to generalise to non-linear models. For the purpose of this document, we shall focus on <em>polynomial</em> models, as follows:</p>

<div class="alert alert-success" role="alert"><p><strong>(Degree-$k$) Polynomial Regression:</strong> Given $n$ points $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$, find coefficients $a_0, a_1, \ldots, a_k$ such that for the model</p>
<p>$$
f(x) = a_0 + a_1x + a_2x^2 + \ldots + a_kx^k = \sum_{i=0}^k a_ix^i
$$</p>
<p>, the RMS</p>
<p>$$
E_2(f) = \sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - f(x_i))^2}
$$</p>
<p>is minimized.</p>
</div>

<p>To help understand, here is an example.</p>
<p><strong>Example 1:</strong> Suppose that we have four data points $(0, 1), (1, 5), (2, 7), (4, 4)$, and we wish to closely model this with a quadratic model. Then, $k = 2$ and we wish to find coefficients $a_0, a_1, a_2$ such that</p>
<p>$$\begin{align*}
E_2(f) &amp;= \sqrt{\frac{1}{n}\sum_{i=1}^n(y_i - f(x_i))^2} \\ &amp;= \sqrt{\frac{1}{4}\left((1 - f(0))^2 + (5 - f(1))^2 + (7 - f(2))^2 + (4 - f(4))^2\right)} \\ &amp;= \sqrt{\frac{1}{4}(4a_0^2 + 14a_0a_1 + 21a_1^2 + 42a_0a_2 + 146a_1a_2 + 273a_2^2 - 34a_0 - 70a_1 - 194a_2 + 91)}
\end{align*}$$</p>
<p>is minimised. Of course it looks impossible to solve right now, as we have $3$ variables and a total of $10$ terms to minimise together. However, we will solve the minimisation problem in section 4.</p>
<p><figure 
	>
	<a href="https://i.imgur.com/0lRE0Zk.png" >
		<img src="https://i.imgur.com/0lRE0Zk.png"
			
			
			
			loading="lazy"
			>
	</a>
	
</figure></p>
<hr>
<h2 id="3-lagrange-multiplier">3. Lagrange Multiplier</h2>
<p>To minimise the absolute mess above, we will require another tool. Recall that in normal calculus, it is find the local minimum any function, say $f(x) = x^3 + 3x^2 - 5$ - we differentiate it to get $f&rsquo;(x) = 3x^2 + 6x$, then find it&rsquo;s zeroes $f&rsquo;(x) = 3x(x + 2) \implies x = 0, -2$, and finally check that $f&rsquo;&rsquo;(x) &gt; 0$ to get that $x = 0$ is a local minimum of $f$. We wish to do something like that with more than one variables!</p>
<p>This is when Lagrange can help us. In the 18th and early 19th century, Lagrange developed a tool called the Lagrange Multiplier to solve such optimisation problems. The details of <em>when</em> it is applicable is complicated, but for our purpose, we will present a simplified version.</p>
<p>Firstly, we need a notion of &ldquo;derivative&rdquo; when there are more than one variable. It will be simplier to demonstrate by an example than to rigorously define it. Take a function $f(x, y) = x^2 + 5xy + 3y$. We define the <em>partial derivative with respect to $x$</em>, denoted $\frac{\partial f}{\partial x}$ as taking the normal derivative, except that we treat every variable except $x$ as a constant. In this case, this means $y$ is a constant (like $2$ is), and we get</p>
<p>$$\frac{\partial f}{\partial x} = \underbrace{2x}_{x^2} + \underbrace{5y}_{5xy} + \underbrace{0}_{3y}$$</p>
<p>Similarly, we can also do this for other variables:</p>
<p>$$\frac{\partial f}{\partial y} = \underbrace{0}_{x^2} + \underbrace{5x}_{5xy} + \underbrace{3}_{3y}$$</p>
<p>As you see, this is essentially the same as the normal derivatives - we simply fix one variable and ignore the other variables.</p>
<p>With this, we can state what Lagrange derived:</p>

<div class="alert alert-info" role="alert"><p><strong>Theorem (Simplified):</strong> Suppose that $f$ is a function in terms of $x_1, x_2, \ldots, x_k$. Then, at where $f(x_1, x_2, \ldots, x_k)$ achieves local minimum or maximum, we must have</p>
<p>$$
\frac{\partial f}{\partial x_1} = \frac{\partial f}{\partial x_2} = \cdots = \frac{\partial f}{\partial x_k} = 0
$$</p>
</div>

<p>For example, with our function of $f(x, y) = x^2 + 5xy + 3y$, we can find it&rsquo;s local extremas by setting $2x + 5y = 5x + 3 = 0$ and solving the equations.</p>
<p>With this, we can go back and solve the minimization problem in Section 2.</p>
<hr>
<h2 id="section-4-finding-the-model">Section 4: Finding the Model</h2>
<p>In Section 2, we arrived at the formalisation of the problem, which requires us to minimise the following scary looking formula:</p>
<p>$$
E_2(f) = \sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - f(x_i))^2}
$$</p>
<p>To do this, first notice that it suffices to minimise the term $\sum_{i=1}^n (y_i - f(x_i))^2$, since multiplying by a constant $\frac{1}{n}$ and taking square root does not change the minimality of the term. Hence, we minimise</p>
<p>$$
R_2(f) = \sum_{i=1}^n (y_i - f(x_i))^2
$$</p>
<p>where $f(x) = a_0 + a_1x + \cdots + a_kx^k = \sum_{j=0}^k a_jx^j$. Now applying Lagrange&rsquo;s Theorem, we require</p>
<p>$$
\frac{\partial R_2}{\partial a_0} = \frac{\partial R_2}{\partial a_1} = \cdots = \frac{\partial R_2}{\partial a_k} = 0
$$</p>
<p>What does each of these terms equal to? Well, for a particular index $j$,</p>
<p>$$
\frac{\partial R_2}{\partial a_j} = \frac{\partial}{\partial a_j} \sum_{i=1}^n (\color{red}{y_i - f(x_i)})^{\color{cyan}{2}}
$$</p>
<p>We can apply the chain rule on the second term. Recall that the normal chain rule states $\frac{d}{dx} f(g(x)) = f&rsquo;(g(x))\cdot g&rsquo;(x)$. Here, it is exactly the same. Apply $f(x) = x^2$ and $g(x) = y_i - f(x_i)$,</p>
<p>$$
\frac{\partial R_2}{\partial a_j} = \sum_{i=1}^n \underbrace{\color{cyan}{2(\color{red}{y_i - f(x_i)})}}<em>{f&rsquo;(g)}\cdot\underbrace{\frac{\partial}{\partial a_j}(\color{red}{y_i - f(x_i)})}</em>{g&rsquo;} = -\sum_{i=1}^n 2(y_i - f(x_i))\cdot\frac{\partial f}{\partial a_j}(x_i)
$$</p>
<p>Finally, we know that $f(x) = a_0 + a_1x + \cdots + a_kx^k$. Therefore, if we take partial derivative w.r.t. $a_i$, which means treating every other variable as constant, then we are left with $\frac{\partial f}{\partial a_j} = \frac{\partial}{\partial a_j}(a_ix^i + \text{constant}) = x^i$. Therefore,</p>
<p>$$
\frac{\partial R_2}{\partial a_j} = -2\sum_{i=1}^n (y_i - f(x_i)) x_i^j
$$</p>
<p>And hence, our problem reduces to solving</p>
<p>$$
\sum_{i=1}^n (y_i - f(x_i)) = \sum_{i=1}^n (y_i - f(x_i))x_i = \cdots = \sum_{i=1}^n (y_i - f(x_i))x_i^k = 0
$$</p>
<p>This still looks scary, but let&rsquo;s look back at our example.</p>
<p><strong>Example 1 (Cont.):</strong> We had ${(0, 1), (1, 5), (2, 7), (4, 4)}$ as our data points, and $f(x) = a_0 + a_1x + a_2x^2$. Therefore, we want to solve the folllowing system of equations:</p>
<p>$$\begin{cases}\begin{align*}
&amp;\sum_{i=1}^n (y_i - f(x_i)) = (1 - a_0) + \cdots + (4 - (a_0 + 4a_1 + 16a_2)) &amp;= 17 - 4a_0 - 7a_1 - 21a_2 = 0 \
&amp;\sum_{i=1}^n (y_i - f(x_i))x_i = \cdots &amp;= 35 - 7a_0 - 21a_1 - 73a_2 = 0 \
&amp;\sum_{i=1}^n (y_i - f(x_i))x_i^2 = \cdots &amp;= 97 - 21a_0 - 73a_1 - 273a_2 = 0 \
\end{align*}\end{cases}$$</p>
<p>Since there are three variables and three equations, we can solve this using normal system of equations! Indeed, we get $(a_0, a_1, a_2) = \left(\frac{107}{110}, \frac{1147}{220}, -\frac{49}{44}\right) \approx (0.97, 5.21, -1.11)$, which matches the coefficients of Desmos.</p>
<hr>
<h2 id="5-code">5. Code</h2>
<p>To aid computation, we coded up a program in a programming language called Sage. It is a library extension of Python. In Sage, solving linear equations are easy: we first transform the coefficients into a <code>Matrix</code>, then call the function <code>.solve_right</code> to solve the equations - see <a class="link" href="https://doc.sagemath.org/html/en/tutorial/tour_linalg.html"  target="_blank" rel="noopener"
    >docs</a> for more details.</p>
<p>Anyways, here is the final code:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">find_coeffs</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># arguments:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># points: [(x_1, y_1), ..., (x_n, y_n)] in an array</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># k: degree of the polynomial model</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># return values:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># - coefficients a_0, a_1, ..., a_k in an array</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># - also the RMS of the model, E_2(f)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&#34;Not enough data points.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># computing coefficients of a_j</span>
</span></span><span class="line"><span class="cl">    <span class="n">x_coeff_matrix</span> <span class="o">=</span> <span class="n">Matrix</span><span class="p">(</span><span class="n">QQ</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x_sum_of_powers</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="n">i</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">points</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">x_coeff_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_sum_of_powers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># computing the constant terms of y_i</span>
</span></span><span class="line"><span class="cl">    <span class="n">y_coeff_matrix</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">y_coeff_matrix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span><span class="o">^</span><span class="n">i</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">points</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">y_coeff_matrix</span> <span class="o">=</span> <span class="n">vector</span><span class="p">(</span><span class="n">QQ</span><span class="p">,</span> <span class="n">y_coeff_matrix</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># solving system of linear equations</span>
</span></span><span class="line"><span class="cl">    <span class="n">coef</span> <span class="o">=</span> <span class="n">x_coeff_matrix</span><span class="o">.</span><span class="n">solve_right</span><span class="p">(</span><span class="n">y_coeff_matrix</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># computing residuals and RMS</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a_i</span> <span class="o">*</span> <span class="n">x</span><span class="o">^</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">a_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">coef</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">residuals</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_i</span> <span class="o">-</span> <span class="n">f</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span> <span class="ow">in</span> <span class="n">points</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">RMS</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">r</span><span class="o">^</span><span class="mi">2</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">residuals</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">coef</span><span class="o">.</span><span class="n">n</span><span class="p">(),</span> <span class="n">RMS</span><span class="o">.</span><span class="n">n</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># data points</span>
</span></span><span class="line"><span class="cl">    <span class="n">arr</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># linear regression</span>
</span></span><span class="line"><span class="cl">    <span class="n">coef</span><span class="p">,</span> <span class="n">RMS</span> <span class="o">=</span> <span class="n">find_coeffs</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;coef =&#34;</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;RMS =&#34;</span><span class="p">,</span> <span class="n">RMS</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># quadratic regression</span>
</span></span><span class="line"><span class="cl">    <span class="n">coef</span><span class="p">,</span> <span class="n">RMS</span> <span class="o">=</span> <span class="n">find_coeffs</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;coef =&#34;</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;RMS =&#34;</span><span class="p">,</span> <span class="n">RMS</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">main</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">Output:
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Linear Regression:
</span></span></span><span class="line"><span class="cl"><span class="s2">- coef = (3.20000000000000, 0.600000000000000)
</span></span></span><span class="line"><span class="cl"><span class="s2">- RMS = 1.97484176581315
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">Quadratic Regression:
</span></span></span><span class="line"><span class="cl"><span class="s2">- coef = (0.972727272727273, 5.21363636363636, -1.11363636363636)
</span></span></span><span class="line"><span class="cl"><span class="s2">- RMS = 0.0476731294622796
</span></span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;</span>
</span></span></code></pre></div><hr>
<h2 id="6-future">6. Future</h2>
<p>It is easy to extend the work to other models or using other error measures other than $E_2$, and I would love to investigate this further in other fields such as the $p$-adic integers.</p>

</section>


    <footer class="article-footer">
    

    </footer>


    
    
    
</article>

    <aside class="related-contents--wrapper">
    
    
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2021 - 
        
        2023 Blog by grhkm21
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.2.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">Table of contents</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#1-linear-regression">1. Linear Regression</a></li>
    <li><a href="#2-polynomial-regression">2. Polynomial Regression</a></li>
    <li><a href="#3-lagrange-multiplier">3. Lagrange Multiplier</a></li>
    <li><a href="#section-4-finding-the-model">Section 4: Finding the Model</a></li>
    <li><a href="#5-code">5. Code</a></li>
    <li><a href="#6-future">6. Future</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
